### 交叉验证

#### 为什么需要交叉验证？
在机器学习里，通常来说我们不能将全部数据用于训练模型，否则我们将没有数据集对该模型进行验证，从而评估我们的模型的预测效果。第一种方法最简单(test set approach)，把整个数据集分成两部分，一部分用于训练，一部分用于验证，这也就是我们经常提到的训练集（training set）和测试集（test set）。但缺点在于

1. **最终模型与参数的选取将极大程度依赖于你对训练集和测试集的划分方法**

![image](https://raw.githubusercontent.com/CPS-zhangX/PhD-Study/master/images/MSEcrossvalidation.png)

十种不同的训练集和测试集划分方法得到的test MSE，可以看到，在不同的划分方法下，test MSE的变动是很大的。所以如果我们的训练集和测试集的划分方法不够好，很有可能无法选择到最好的模型与参数。

2. **只能使用部分数据进行训练**，无法充分利用已有数据，模型效果可能受到影响。

这种情况对于**数据不是很充足**的情况，尤为明显。（刘建平：在我日常项目里面，对于普通适中问题，如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Training Set），一份为验证集（Validation Set），最后一份为测试集（Test Set））

#### 分类

1. **简单交叉验证**：随机的将样本数据分为两部分（比如： 70%的训练集，30%的测试集），然后用训练集来训练模型，在测试集上验证模型及参数。接着，我们再把样本打乱，重新选择训练集和测试集，继续训练数据和检验模型。最后我们选择损失函数评估最优的模型和参数。　

2. **k-Folder cross validation**：k折交叉验证会把样本数据随机的分成k份，每次随机的选择k-1份作为训练集，剩下的1份做测试集。当这一轮完成后，重新随机选择k-1份来训练数据。若干轮（小于k）之后，选择损失函数评估最优的模型和参数。（**每次训练都是独立的，并不是在之前的基础上**）

3. **Leave-one-out cross validation**：k-folder的特殊情况。此时k=样本数。**这种方法主要用于样本非常少的时候**。

4. **bootstrapping 自助法**：也是用于**样本特别少**的情况。比如我们有m个样本（m较小），每次在这m个样本中随机采集一个样本，放入训练集，采样完后把样本放回。这样重复采集m次，我们得到m个样本组成的训练集。当然，这m个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集。这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。

#### 交叉验证和过拟合
由于交叉验证使用的训练集每次都不相同，模型的泛化能力强，对过拟合现象有效。


- [1] [机器学习中如何用交叉验证来验证是否过拟合？](https://www.zhihu.com/question/23578594)

- [2] [交叉验证原理小结](https://www.cnblogs.com/pinard/p/5992719.html)

- [3] [Cross-Validation（交叉验证）详解](https://zhuanlan.zhihu.com/p/24825503)


